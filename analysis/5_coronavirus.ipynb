{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171634, 34)\n"
     ]
    }
   ],
   "source": [
    "df_x = pd.read_csv(\"Data/df_x_nb4a-mis.csv\", index_col = 0)\n",
    "print(df_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['text'] = df_x['text'].fillna('')\n",
    "df_x['textlower'] = df_x['textlower'].fillna('')\n",
    "df_x['message_dt'] = pd.to_datetime(df_x[\"message_dt\"], format='%Y-%m-%d %H:%M:00')\n",
    "df_x['message_date'] = pd.to_datetime(df_x[\"message_date\"], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['coronavirus'] = df_x['textlower'].str.contains('corona') & df_x['textlower'].str.contains('virus')\n",
    "df_x['virus'] = df_x['textlower'].str.contains('virus')\n",
    "df_x['frontera'] = df_x['textlower'].str.contains('frontera')\n",
    "df_x['troch'] = df_x['textlower'].str.contains('troch')\n",
    "df_x['cuarentena'] = df_x['textlower'].str.contains('cuarentena')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select messages 5+ words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['5_word'] = df_x['textlower'].apply(lambda x: x.count(' ') >= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df_x[df_x['5_word']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coronavirus = df_y[['message_date', 'coronavirus']].groupby('message_date').mean()\n",
    "virus = df_y[['message_date', 'virus']].groupby('message_date').mean()\n",
    "frontera = df_y[['message_date', 'frontera']].groupby('message_date').mean()\n",
    "troch = df_y[['message_date', 'troch']].groupby('message_date').mean()\n",
    "cuarentena = df_y[['message_date', 'cuarentena']].groupby('message_date').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/pandas/plotting/_matplotlib/converter.py:103: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "ax.plot(coronavirus * 100, label = '\"Coronavirus\"')\n",
    "ax.plot(virus * 100, label = '\"Virus\"')\n",
    "ax.plot(cuarentena * 100, label = '\"Cuarentena\"')\n",
    "\n",
    "plt.xlabel(\"UTC-5 / Colombia Time\")\n",
    "plt.ylabel(\"% of 5+ Word Messages\")\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval = 14))\n",
    "ax.legend()\n",
    "plt.xticks(horizontalalignment = 'center', rotation = '0')\n",
    "plt.savefig('images/ch-coronavirus/5word_proportion.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (14, 6))\n",
    "ax.axvline(x = pd.Timestamp(2020, 3, 13), color = 'r', lw = 3)\n",
    "ax.plot(coronavirus * 100, label = '\"Coronavirus\"')\n",
    "ax.plot(frontera * 100, label = '\"Frontera\"')\n",
    "ax.plot(troch * 100, label = '\"Troch\"')\n",
    "\n",
    "plt.xlabel(\"UTC-5 / Colombia Time\")\n",
    "plt.ylabel(\"% of 5+ Word Messages\")\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval = 14))\n",
    "ax.legend()\n",
    "plt.xticks(horizontalalignment = 'center', rotation = '0')\n",
    "plt.savefig('images/ch-coronavirus/5word_proportion_border.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002578471482105408\n",
      "0.012239144635060336\n"
     ]
    }
   ],
   "source": [
    "print(df_y[df_y['message_date'] < pd.Timestamp(2020, 3, 13)]['troch'].mean())\n",
    "print(df_y[df_y['message_date'] < pd.Timestamp(2020, 3, 13)]['frontera'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002592307153366496\n",
      "0.023652694610778444\n",
      "Ttest_indResult(statistic=-19.398686793340286, pvalue=1.4232135978179732e-83)\n",
      "0.012593708400476423\n",
      "0.05778443113772455\n",
      "Ttest_indResult(statistic=-20.896377194931382, pvalue=1.271070353178447e-96)\n"
     ]
    }
   ],
   "source": [
    "outside = df_y[(df_y['message_date'] < pd.Timestamp(2020, 3, 13)) \\\n",
    "               | (df_y['message_date'] > pd.Timestamp(2020, 3, 15))]\n",
    "inside = df_y[(df_y['message_date'] >= pd.Timestamp(2020, 3, 13)) \\\n",
    "              & (df_y['message_date'] <= pd.Timestamp(2020, 3, 15))]\n",
    "\n",
    "print(outside['troch'].mean())\n",
    "print(inside['troch'].mean())\n",
    "\n",
    "print(ttest_ind(outside['troch'], inside['troch']))\n",
    "\n",
    "print(outside['frontera'].mean())\n",
    "print(inside['frontera'].mean())\n",
    "\n",
    "print(ttest_ind(outside['frontera'], inside['frontera']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "virus = df_x[['uid', 'message_date', 'virus']].groupby(['uid', 'message_date']).sum() > 0\n",
    "coronavirus = df_x[['uid', 'message_date', 'coronavirus']].groupby(['uid', 'message_date']).sum() > 0\n",
    "frontera = df_x[['uid', 'message_date', 'frontera']].groupby(['uid', 'message_date']).sum() > 0\n",
    "troch = df_x[['uid', 'message_date', 'troch']].groupby(['uid', 'message_date']).sum() > 0\n",
    "cuarentena = df_x[['uid', 'message_date', 'cuarentena']].groupby(['uid', 'message_date']).sum() > 0\n",
    "\n",
    "virus = virus.groupby('message_date').mean()\n",
    "coronavirus = coronavirus.groupby('message_date').mean()\n",
    "frontera = frontera.groupby('message_date').mean()\n",
    "troch = troch.groupby('message_date').mean()\n",
    "cuarentena = cuarentena.groupby('message_date').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (14, 6))\n",
    "ax.axvline(x = pd.Timestamp(2020, 3, 13), color = 'r', lw = 3)\n",
    "ax.plot(coronavirus * 100, label = '\"Coronavirus\"')\n",
    "ax.plot(frontera * 100, label = '\"Frontera\"')\n",
    "ax.plot(troch * 100, label = '\"Troch\"')\n",
    "\n",
    "plt.xlabel(\"UTC-5 / Colombia Time\")\n",
    "plt.ylabel(\"% of Active Groups with Keyword\")\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval = 14))\n",
    "ax.legend()\n",
    "plt.xticks(horizontalalignment = 'center', rotation = '0')\n",
    "plt.savefig('images/ch-coronavirus/group_proportion.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# % of user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "virus = df_x[['tel', 'message_date', 'virus']].groupby(['tel', 'message_date']).sum() > 0\n",
    "coronavirus = df_x[['tel', 'message_date', 'coronavirus']].groupby(['tel', 'message_date']).sum() > 0\n",
    "frontera = df_x[['tel', 'message_date', 'frontera']].groupby(['tel', 'message_date']).sum() > 0\n",
    "troch = df_x[['tel', 'message_date', 'troch']].groupby(['tel', 'message_date']).sum() > 0\n",
    "cuarentena = df_x[['tel', 'message_date', 'cuarentena']].groupby(['tel', 'message_date']).sum() > 0\n",
    "\n",
    "virus = virus.groupby('message_date').mean()\n",
    "coronavirus = coronavirus.groupby('message_date').mean()\n",
    "frontera = frontera.groupby('message_date').mean()\n",
    "troch = troch.groupby('message_date').mean()\n",
    "cuarentena = cuarentena.groupby('message_date').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (14, 6))\n",
    "ax.axvline(x = pd.Timestamp(2020, 3, 13), color = 'r', lw = 3)\n",
    "ax.plot(coronavirus * 100, label = '\"Coronavirus\"')\n",
    "ax.plot(frontera * 100, label = '\"Frontera\"')\n",
    "ax.plot(troch * 100, label = '\"Troch\"')\n",
    "\n",
    "plt.xlabel(\"UTC-5 / Colombia time\")\n",
    "plt.ylabel(\"% of Active Users\\nWho Discuss Keyword\")\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval = 14))\n",
    "ax.legend()\n",
    "plt.xticks(horizontalalignment = 'center', rotation = '0')\n",
    "plt.savefig('images/ch-coronavirus/user_proportion.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users with meaningful text messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "virus = df_y[['tel', 'message_date', 'virus']].groupby(['tel', 'message_date']).sum() > 0\n",
    "coronavirus = df_y[['tel', 'message_date', 'coronavirus']].groupby(['tel', 'message_date']).sum() > 0\n",
    "frontera = df_y[['tel', 'message_date', 'frontera']].groupby(['tel', 'message_date']).sum() > 0\n",
    "troch = df_y[['tel', 'message_date', 'troch']].groupby(['tel', 'message_date']).sum() > 0\n",
    "cuarentena = df_y[['tel', 'message_date', 'cuarentena']].groupby(['tel', 'message_date']).sum() > 0\n",
    "\n",
    "virus = virus.groupby('message_date').mean()\n",
    "coronavirus = coronavirus.groupby('message_date').mean()\n",
    "frontera = frontera.groupby('message_date').mean()\n",
    "troch = troch.groupby('message_date').mean()\n",
    "cuarentena = cuarentena.groupby('message_date').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (14, 6))\n",
    "ax.axvline(x = pd.Timestamp(2020, 3, 13), color = 'r', lw = 3)\n",
    "ax.plot(coronavirus * 100, label = '\"Coronavirus\"')\n",
    "ax.plot(frontera * 100, label = '\"Frontera\"')\n",
    "ax.plot(troch * 100, label = '\"Troch\"')\n",
    "\n",
    "plt.xlabel(\"UTC-5 / Colombia time\")\n",
    "plt.ylabel(\"% of Active Users\\nWho Discuss Keyword\")\n",
    "plt.title(\"Users Who Send 5+ Word Text Messages\")\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval = 14))\n",
    "ax.legend()\n",
    "plt.xticks(horizontalalignment = 'center', rotation = '0')\n",
    "plt.savefig('images/ch-coronavirus/user_proportion_text.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = pd.read_csv('Data/df_groups_nb4c-scam.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_troch_pre = df_x[(df_x['message_date'] <= pd.Timestamp(2020, 3, 12)) & df_x['troch']]['uid'].unique()\n",
    "group_troch_after = df_x[(df_x['message_date'] >= pd.Timestamp(2020, 3, 13)) & df_x['troch']]['uid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups['troch_pre'] = False\n",
    "df_groups.loc[group_troch_pre, 'troch_pre'] = True\n",
    "\n",
    "df_groups['troch_after'] = 0 # SMF requires numeric\n",
    "df_groups.loc[group_troch_after, 'troch_after'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(df_groups['troch_pre'].sum())\n",
    "print(df_groups['troch_after'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Size', 'pVZ', 'pCO', 'pUS',\n",
    "       'pPE', 'pCL', 'pEC', 'p3rdCountry', 'entropy', 'activity',\n",
    "       'degree', 'hhConc', 'gini',\n",
    "       'replies_n', 'virality', 'fakeNews', 'fakeNews_users', 'scam',\n",
    "       'scam_users', 'troch_pre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Size =============\n",
      "(0.40918779889670226, 2.0699540250112056e-08)\n",
      "============= pVZ =============\n",
      "(0.36960474046093744, 5.189790706303542e-07)\n",
      "============= pCO =============\n",
      "(-0.2050623829257252, 0.0066402129818484935)\n",
      "============= pUS =============\n",
      "(-0.07808289272946727, 0.30577636173002937)\n",
      "============= pPE =============\n",
      "(0.02311428909307101, 0.7620870724780106)\n",
      "============= pCL =============\n",
      "(0.11585469802079935, 0.1279228445579995)\n",
      "============= pEC =============\n",
      "(0.015213566845745763, 0.8420704740303421)\n",
      "============= p3rdCountry =============\n",
      "(-0.05883352763086867, 0.44062270726230224)\n",
      "============= entropy =============\n",
      "(0.11759738690393114, 0.12224894858901159)\n",
      "============= activity =============\n",
      "(0.09769788429728969, 0.19966550029934713)\n",
      "============= degree =============\n",
      "(0.22236252328880474, 0.0031876955908943473)\n",
      "============= hhConc =============\n",
      "(-0.21791991206988387, 0.0038691061777596995)\n",
      "============= gini =============\n",
      "(0.3272387033781887, 1.046062016735444e-05)\n",
      "============= replies_n =============\n",
      "(0.011562075545629635, 0.8796443949325436)\n",
      "============= virality =============\n",
      "(0.10670979615131151, 0.16107713509011537)\n",
      "============= fakeNews =============\n",
      "(-0.015495649086381354, 0.8391814956282548)\n",
      "============= fakeNews_users =============\n",
      "(0.1508199701860354, 0.04697889863297336)\n",
      "============= scam =============\n",
      "(-0.14648406053096896, 0.05376224275580397)\n",
      "============= scam_users =============\n",
      "(-0.09210918404702881, 0.2267329094751771)\n",
      "============= troch_pre =============\n",
      "(0.5217573349000768, 1.5527424018677899e-13)\n"
     ]
    }
   ],
   "source": [
    "for col in cols:\n",
    "    print(\"============= %s =============\" % col)\n",
    "    print(scipy.stats.pearsonr(df_groups[col], df_groups['troch_after']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.198750\n",
      "         Iterations 9\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            troch_after   No. Observations:                  174\n",
      "Model:                         Probit   Df Residuals:                      166\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Sun, 12 Apr 2020   Pseudo R-squ.:                  0.4911\n",
      "Time:                        22:46:24   Log-Likelihood:                -34.582\n",
      "converged:                       True   LL-Null:                       -67.950\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.732e-12\n",
      "=====================================================================================\n",
      "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept            -4.2230      1.119     -3.775      0.000      -6.416      -2.030\n",
      "troch_pre[T.True]     1.5696      0.480      3.271      0.001       0.629       2.510\n",
      "Size                  0.0037      0.003      1.472      0.141      -0.001       0.009\n",
      "pVZ                   3.3837      0.983      3.444      0.001       1.458       5.309\n",
      "pCO                   0.9074      0.728      1.246      0.213      -0.519       2.334\n",
      "degree                0.0013      0.006      0.200      0.842      -0.011       0.014\n",
      "hhConc               -1.0468      1.206     -0.868      0.385      -3.411       1.317\n",
      "gini                  2.4242      1.331      1.821      0.069      -0.185       5.034\n",
      "=====================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.17 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "reg = smf.probit('troch_after ~ troch_pre + Size + pVZ + pCO + degree + hhConc + gini', data = df_groups).fit()\n",
    "print(reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Probit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:            troch_after\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "=====================================================================================\n",
      "                       dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "troch_pre[T.True]     0.1701      0.047      3.611      0.000       0.078       0.262\n",
      "Size                  0.0004      0.000      1.479      0.139      -0.000       0.001\n",
      "pVZ                   0.3668      0.099      3.717      0.000       0.173       0.560\n",
      "pCO                   0.0984      0.078      1.255      0.209      -0.055       0.252\n",
      "degree                0.0001      0.001      0.200      0.841      -0.001       0.001\n",
      "hhConc               -0.1135      0.129     -0.877      0.380      -0.367       0.140\n",
      "gini                  0.2628      0.143      1.836      0.066      -0.018       0.543\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(reg.get_margeff().summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_vzwa)",
   "language": "python",
   "name": "conda_vzwa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
