{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast # string rep. of list to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171634, 30)\n"
     ]
    }
   ],
   "source": [
    "df_x = pd.read_csv('Data/df_x_nb3-reply.csv', index_col=0)\n",
    "print(df_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['reply_link'] = df_x['reply_link'].astype(pd.Int32Dtype())\n",
    "df_x['reply_list'] = df_x['reply_list'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['message_dt'] = pd.to_datetime(df_x[\"message_dt\"], format='%Y-%m-%d %H:%M:00')\n",
    "df_x['message_date'] = pd.to_datetime(df_x[\"message_date\"], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = {}\n",
    "root_connected = {}\n",
    "root_diameter = {}\n",
    "root_virality = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df_x[df_x['reply_link'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_r.iterrows():\n",
    "    # construct graph\n",
    "    adjacency_matrix[index] = [row['reply_link']]\n",
    "    adjacency_matrix[row['reply_link']] = adjacency_matrix.get(row['reply_link'], []) + [index]\n",
    "    \n",
    "    # attribute to root\n",
    "    root = row['reply_list'][0]\n",
    "    root_connected[root] = root_connected.get(root, []) + [index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root in root_connected:\n",
    "    root_connected[root] += [root]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root in root_connected:\n",
    "    components = root_connected[root]\n",
    "    n = len(components)\n",
    "    dist_matrix = np.zeros((n,n))\n",
    "    for i in range(n-1):\n",
    "        # BFS\n",
    "        discovered = [False] * n\n",
    "        distances = [0] * n\n",
    "        \n",
    "        # Label start\n",
    "        queue = [i]\n",
    "        discovered[i] = True\n",
    "                \n",
    "        while len(queue) > 0:\n",
    "            vi = queue.pop(0)\n",
    "                        \n",
    "            neighbors_i = [components.index(x) for x in adjacency_matrix[components[vi]]]\n",
    "            for ni in neighbors_i:\n",
    "                if not discovered[ni]:\n",
    "                    discovered[ni] = True\n",
    "                    queue.append(ni)\n",
    "                    distances[ni] = distances[vi] + 1\n",
    "        dist_matrix[i] = distances\n",
    "        dist_matrix[:, i] = distances\n",
    "        \n",
    "    root_diameter[root] = np.max(dist_matrix)\n",
    "    root_virality[root] = np.mean(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "df_r['virality'] = df_r['reply_list'].apply(lambda x: root_virality[x[0]])\n",
    "df_r['diameter'] = df_r['reply_list'].apply(lambda x: root_diameter[x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['virality'] = df_r['virality']\n",
    "df_x['virality'] = df_x['virality'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_i = (df_x['virality'] == 0) & (df_x['replies_n'] > 0)\n",
    "df_x.loc[root_i, 'virality'] =\\\n",
    "    df_x.loc[root_i].index.map(lambda x: root_virality[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x.to_csv('Data/df_x_nb3b-virality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['diameter'] = df_r['diameter']\n",
    "df_x['diameter'] = df_x['diameter'].fillna(0)\n",
    "\n",
    "df_x.loc[root_i, 'diameter'] =\\\n",
    "    df_x.loc[root_i].index.map(lambda x: root_diameter[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview - Virality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x[(df_x['replies_n'] > 0) & (df_x['reply_link'].isnull())]['virality'].hist(bins = 30)\n",
    "plt.xlabel(\"Virality\")\n",
    "plt.ylabel(\"# of Cascades\")\n",
    "plt.title(\"Unique Reply Cascades\")\n",
    "plt.savefig('images/ch-replycascades/hist_virality.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_x[(df_x['replies_n'] > 0) & (df_x['reply_link'].isnull())]['replies_n'],\n",
    "             df_x[(df_x['replies_n'] > 0) & (df_x['reply_link'].isnull())]['virality'], alpha = 0.3)\n",
    "plt.xlabel(\"# of Replies\")\n",
    "plt.ylabel(\"Virality\")\n",
    "plt.title(\"Root Nodes\")\n",
    "plt.savefig('images/ch-replycascades/scatter_root_repliesn_virality.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images actually more viral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=15.34552101877468, pvalue=4.5857007455330665e-53)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(df_x[df_x['image'].notnull() & (df_x['virality'] > 0)]['virality'],\n",
    "            df_x[(df_x['text'] != '') & (df_x['virality'] > 0)]['virality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7142182236946955\n",
      "1.5019615678654146\n"
     ]
    }
   ],
   "source": [
    "# Images go more viral!\n",
    "print(np.mean(df_x[df_x['image'].notnull() & (df_x['virality'] > 0)]['virality']))\n",
    "print(np.mean(df_x[(df_x['text'] != '') & (df_x['virality'] > 0)]['virality']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VZ actually more viral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-6.592070354761768, pvalue=4.386280849302184e-11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(df_x[(df_x['virality'] > 0) & (df_x['tel'].str.startswith('+57'))]['virality'],\n",
    "            df_x[(df_x['virality'] > 0) & (df_x['tel'].str.startswith('+58'))]['virality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.44997091549334\n",
      "1.5357922108782354\n"
     ]
    }
   ],
   "source": [
    "# Closer, which makes sense!\n",
    "print(np.mean(df_x[(df_x['virality'] > 0) & (df_x['tel'].str.startswith('+57'))]['virality']))\n",
    "print(np.mean(df_x[(df_x['virality'] > 0) & (df_x['tel'].str.startswith('+58'))]['virality']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_x['diameter'], df_x['virality'])\n",
    "plt.xlabel(\"Diameter\")\n",
    "plt.ylabel(\"Virality\")\n",
    "plt.title(\"All Messages\")\n",
    "plt.savefig('images/ch-replycascades/scatter_diameter_virality.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = pd.read_csv('Data/df_groups_nb3a-reply.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups['virality'] = df_x[df_x['virality'] > 0][['uid', 'virality']].groupby('uid').mean()\n",
    "df_groups['virality'] = df_groups['virality'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups.to_csv('Data/df_groups_nb3b-virality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups['virality'].hist(bins = 20)\n",
    "plt.title(\"All Groups\")\n",
    "plt.xlabel(\"Avg. Virality\\n(Within Cascades)\")\n",
    "plt.ylabel(\"# of Groups\")\n",
    "plt.savefig('images/ch-replycascades/hist_group_virality.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9038850128124559, 2.4889221316363124e-65)\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(df_groups['replies_n'], df_groups['virality'], alpha = 0.3)\n",
    "plt.xlabel(\"Avg. Number of Replies\")\n",
    "plt.ylabel(\"Avg. Virality\\n(Within Cascades)\")\n",
    "plt.title(\"All Groups\")\n",
    "plt.savefig('images/ch-replycascades/scatter_group_repliesn_virality.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()\n",
    "print(scipy.stats.pearsonr(df_groups['replies_n'], df_groups['virality']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               virality   R-squared:                       0.474\n",
      "Model:                            OLS   Adj. R-squared:                  0.465\n",
      "Method:                 Least Squares   F-statistic:                     51.14\n",
      "Date:                Tue, 14 Apr 2020   Prob (F-statistic):           1.31e-23\n",
      "Time:                        23:52:29   Log-Likelihood:                -119.30\n",
      "No. Observations:                 174   AIC:                             246.6\n",
      "Df Residuals:                     170   BIC:                             259.2\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.5648      0.147      3.830      0.000       0.274       0.856\n",
      "entropy        0.1381      0.068      2.027      0.044       0.004       0.273\n",
      "hhConc        -0.7948      0.173     -4.601      0.000      -1.136      -0.454\n",
      "gini           0.7055      0.200      3.526      0.001       0.310       1.100\n",
      "==============================================================================\n",
      "Omnibus:                       49.033   Durbin-Watson:                   1.572\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              105.839\n",
      "Skew:                           1.267   Prob(JB):                     1.04e-23\n",
      "Kurtosis:                       5.860   Cond. No.                         10.8\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "reg = smf.ols('virality ~ entropy + hhConc + gini',\n",
    "              data = df_groups).fit()\n",
    "print(reg.summary())\n",
    "# strong in HHCONC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               virality   R-squared:                       0.246\n",
      "Model:                            OLS   Adj. R-squared:                  0.227\n",
      "Method:                 Least Squares   F-statistic:                     13.05\n",
      "Date:                Tue, 14 Apr 2020   Prob (F-statistic):           1.97e-07\n",
      "Time:                        23:52:31   Log-Likelihood:                -84.366\n",
      "No. Observations:                 124   AIC:                             176.7\n",
      "Df Residuals:                     120   BIC:                             188.0\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.7623      0.183      4.177      0.000       0.401       1.124\n",
      "entropy        0.2393      0.073      3.257      0.001       0.094       0.385\n",
      "hhConc        -1.1033      0.311     -3.543      0.001      -1.720      -0.487\n",
      "gini           0.4438      0.262      1.694      0.093      -0.075       0.963\n",
      "==============================================================================\n",
      "Omnibus:                       41.594   Durbin-Watson:                   1.659\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               79.517\n",
      "Skew:                           1.470   Prob(JB):                     5.41e-18\n",
      "Kurtosis:                       5.596   Cond. No.                         12.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "reg = smf.ols('virality ~ entropy + hhConc + gini',\n",
    "              data = df_groups[df_groups['replies_n'] > 0]).fit()\n",
    "print(reg.summary())\n",
    "# strong in HHCONC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal properties of reply cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df_r['root'] = df_r['reply_list'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_df = pd.DataFrame(df_x.loc[df_r['root'].values]['message_dt'])\n",
    "root_df.columns = ['first_dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_df['last_dt'] = df_r[['message_dt', 'root']].groupby('root').last()\n",
    "root_df['timespan'] = (root_df['last_dt'] - root_df['first_dt']).dt.total_seconds()\n",
    "root_df['timespan'] = root_df['timespan'] / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_df['virality'] = root_df.index.map(lambda x: root_virality[x])\n",
    "root_df['diameter'] = root_df.index.map(lambda x: root_diameter[x])\n",
    "root_df['size'] = root_df.index.map(lambda x: len(root_connected[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017917869017981484\n",
      "(0.042380158229362426, 6.410351086646129e-19)\n"
     ]
    }
   ],
   "source": [
    "x = root_df['timespan']\n",
    "y = root_df['size']\n",
    "plt.figure(figsize = (12, 4))\n",
    "plt.scatter(x, y, alpha = 0.1)\n",
    "plt.xlabel(\"Cascade Duration (hours)\")\n",
    "plt.ylabel(\"Size of Cascade\")\n",
    "plt.title(\"All Reply Cascades\")\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b, color = 'orange')\n",
    "plt.savefig('images/ch-replycascades/temporal_size.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()\n",
    "print(m)\n",
    "print(scipy.stats.pearsonr(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5791698020060221\n",
      "(0.15102853858327142, 1.718602979510054e-215)\n"
     ]
    }
   ],
   "source": [
    "x = root_df[root_df['timespan'] < 12]['timespan']\n",
    "y = root_df[root_df['timespan'] < 12]['size']\n",
    "plt.figure(figsize = (12, 4))\n",
    "plt.scatter(x, y, alpha = 0.1)\n",
    "plt.xlabel(\"Cascade Duration (hours)\")\n",
    "plt.ylabel(\"Size of Cascade\")\n",
    "plt.title(\"Cascade with Duration $< 12$ Hours\")\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b, color = 'orange')\n",
    "plt.savefig('images/ch-replycascades/temporal_size_12h.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()\n",
    "print(m)\n",
    "print(scipy.stats.pearsonr(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0031555859136958853\n",
      "(0.03413200616754636, 8.404636191298922e-13)\n"
     ]
    }
   ],
   "source": [
    "x = root_df['timespan']\n",
    "y = root_df['virality']\n",
    "plt.figure(figsize = (12, 4))\n",
    "plt.scatter(x, y, alpha = 0.1)\n",
    "plt.xlabel(\"Cascade Duration (hours)\")\n",
    "plt.ylabel(\"Virality\")\n",
    "plt.title(\"All Reply Cascades\")\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b, color = 'orange')\n",
    "plt.savefig('images/ch-replycascades/temporal_virality.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()\n",
    "print(m)\n",
    "print(scipy.stats.pearsonr(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10223997515601098\n",
      "(0.12065778090466422, 1.0379210282492673e-137)\n"
     ]
    }
   ],
   "source": [
    "x = root_df[root_df['timespan'] < 12]['timespan']\n",
    "y = root_df[root_df['timespan'] < 12]['virality']\n",
    "plt.figure(figsize = (12, 4))\n",
    "plt.scatter(x, y, alpha = 0.1)\n",
    "plt.xlabel(\"Cascade Duration (hours)\")\n",
    "plt.ylabel(\"Virality\")\n",
    "plt.title(\"Cascade with Duration $< 12$ Hours\")\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b, color = 'orange')\n",
    "plt.savefig('images/ch-replycascades/temporal_virality_12h.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()\n",
    "print(m)\n",
    "print(scipy.stats.pearsonr(x, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_vzwa)",
   "language": "python",
   "name": "conda_vzwa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
