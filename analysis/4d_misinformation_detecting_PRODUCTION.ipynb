{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171634, 34)\n"
     ]
    }
   ],
   "source": [
    "df_x = pd.read_csv(\"Data/df_x_nb4a-mis.csv\", index_col = 0)\n",
    "print(df_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['textlower'] = df_x['textlower'].fillna('')\n",
    "df_x['message_dt'] = pd.to_datetime(df_x[\"message_dt\"], format='%Y-%m-%d %H:%M:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text similarity imports/functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re, unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('spanish')\n",
    "remove_punc = str.maketrans(string.punctuation, len(string.punctuation) * \" \")\n",
    "stopwords_ascii = [unidecode.unidecode(w) for w in stopwords.words('spanish')]\n",
    "\n",
    "def tokenize(s):\n",
    "    s = unidecode.unidecode(s)\n",
    "    s = s.translate(remove_punc)\n",
    "    tokens = nltk.word_tokenize(s)\n",
    "    filtered = [w for w in tokens if w not in stopwords_ascii]\n",
    "    return [stemmer.stem(w) for w in filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(x):\n",
    "    return x\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word', tokenizer=dummy, preprocessor=dummy,\n",
    "                            token_pattern=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['token'] = df_x['textlower'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['token_length'] = df_x['token'].apply(len)\n",
    "df_x = df_x[df_x['token_length'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-28 13:48:00\n"
     ]
    }
   ],
   "source": [
    "print(df_x.iloc[int(df_x.shape[0] * 0.8)]['message_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8800, 36)\n",
      "(35225, 36)\n"
     ]
    }
   ],
   "source": [
    "df_test = df_x[df_x['message_dt'] > pd.Timestamp(2020, 3, 28, 13, 48)]\n",
    "df_train = df_x[df_x['message_dt'] <= pd.Timestamp(2020, 3, 28, 13, 48)]\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Properties of scams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-22 10:00:00\n",
      "2020-03-03 13:21:00\n",
      "2020-03-13 11:47:00\n",
      "2020-03-21 11:57:00\n"
     ]
    }
   ],
   "source": [
    "print(df_train.iloc[int(df_train.shape[0] * 0.2)]['message_dt'])\n",
    "print(df_train.iloc[int(df_train.shape[0] * 0.4)]['message_dt'])\n",
    "print(df_train.iloc[int(df_train.shape[0] * 0.6)]['message_dt'])\n",
    "print(df_train.iloc[int(df_train.shape[0] * 0.8)]['message_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns (recall, precision)\n",
    "def rec_pre(trn, tst, clf):\n",
    "    X_trn = vectorizer.fit_transform(trn['token'])\n",
    "    X_tst = vectorizer.transform(tst['token'])\n",
    "\n",
    "    clf.fit(X_trn, trn['scam'])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(tst['scam'], clf.predict(X_tst)).ravel()\n",
    "    return tp / (tp + fn), tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns recall list, precision list\n",
    "\n",
    "def forward_chain(clf, fn = rec_pre):\n",
    "    stat = []\n",
    "    \n",
    "    # Using 0-20% of training, testing on 20-40%\n",
    "    trn = df_train[df_train['message_dt'] <= pd.Timestamp(2020, 2, 22, 10)]\n",
    "    tst = df_train[(df_train['message_dt'] > pd.Timestamp(2020, 2, 22, 10)) \\\n",
    "                      & (df_train['message_dt'] <= pd.Timestamp(2020, 3, 3, 13, 21))]\n",
    "    \n",
    "    stat.append(fn(trn, tst, clf))\n",
    "    \n",
    "    # Using 0-40% of training, testing on 40-60%\n",
    "    trn = df_train[df_train['message_dt'] <= pd.Timestamp(2020, 3, 3, 13, 21)]\n",
    "    tst = df_train[(df_train['message_dt'] > pd.Timestamp(2020, 3, 3, 13, 21)) \\\n",
    "                      & (df_train['message_dt'] <= pd.Timestamp(2020, 3, 13, 11, 47))]\n",
    "\n",
    "    stat.append(fn(trn, tst, clf))\n",
    "    \n",
    "    # Using 0-60% of training, testing on 60-80%\n",
    "    trn = df_train[df_train['message_dt'] <= pd.Timestamp(2020, 3, 13, 11, 47)]\n",
    "    tst = df_train[(df_train['message_dt'] > pd.Timestamp(2020, 3, 13, 11, 47)) \\\n",
    "                      & (df_train['message_dt'] <= pd.Timestamp(2020, 3, 21, 11, 57))]\n",
    "        \n",
    "    stat.append(fn(trn, tst, clf))\n",
    "    \n",
    "    # Using 0-80% of training, testing on 80-100%\n",
    "    trn = df_train[df_train['message_dt'] <= pd.Timestamp(2020, 3, 21, 11, 57)]\n",
    "    tst = df_train[df_train['message_dt'] > pd.Timestamp(2020, 3, 21, 11, 57)]\n",
    "        \n",
    "    stat.append(fn(trn, tst, clf))\n",
    "    \n",
    "    return [s[0] for s in stat], [s[1] for s in stat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 [0.0, 0.026785714285714284, 0.03977272727272727, 0.2109375] [nan, 1.0, 1.0, 1.0]\n",
      "0.6 [0.08247422680412371, 0.08928571428571429, 0.05113636363636364, 0.2109375] [1.0, 1.0, 1.0, 1.0]\n",
      "0.7 [0.09278350515463918, 0.11607142857142858, 0.05113636363636364, 0.2109375] [1.0, 1.0, 1.0, 1.0]\n",
      "0.8 [0.09278350515463918, 0.13392857142857142, 0.056818181818181816, 0.2109375] [1.0, 1.0, 1.0, 1.0]\n",
      "0.9 [0.12371134020618557, 0.13392857142857142, 0.056818181818181816, 0.21875] [1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#Too strong regularization results in not PREDICTING any positives. Specifically:\n",
    "\n",
    "for c in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    clf = LogisticRegression(C = c)\n",
    "    fc = forward_chain(clf)\n",
    "    print(c, fc[0], fc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7...0.85...0...1...2...3...4..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for c in [0.7, 0.85]:\n",
    "    print(\"%s...\" % c, end = '')\n",
    "    clf = LogisticRegression(C = c)\n",
    "    rec, pre = forward_chain(clf)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = c)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = c)\n",
    "    \n",
    "for i in range(0, 5):\n",
    "    c = 10**i\n",
    "    print(\"%s...\" % i, end = '')\n",
    "    clf = LogisticRegression(C = c)\n",
    "    rec, pre = forward_chain(clf)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = \"10^%s\" % i)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = \"10^%s\" % i)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"Logistic Regression with Varying C ($L_2$ Regularization)\")\n",
    "plt.savefig('images/ch-misinformation/ml_log.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7...0.85...0...1...2...3...4..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for c in [0.7, 0.85]:\n",
    "    print(\"%s...\" % c, end = '')\n",
    "    clf = LogisticRegression(penalty = 'l1', C = c, solver = 'liblinear')\n",
    "    rec, pre = forward_chain(clf)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = c)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = c)\n",
    "    \n",
    "for i in range(0, 5):\n",
    "    c = 10**i\n",
    "    print(\"%s...\" % i, end = '')\n",
    "    clf = LogisticRegression(penalty = 'l1', C = c, solver = 'liblinear')\n",
    "    rec, pre = forward_chain(clf)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = \"10^%s\" % i)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = \"10^%s\" % i)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"Logistic Regression with Varying C ($L_1$ Regularization)\")\n",
    "plt.savefig('images/ch-misinformation/ml_log_l1.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5 [0.0, 0.0, 0.0, 0.0] [nan, nan, nan, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4 [0.0, 0.0, 0.0, 0.0] [nan, nan, nan, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3 [0.0, 0.0, 0.0, 0.0] [nan, nan, nan, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2 [0.0, 0.0, 0.0, 0.0] [nan, nan, nan, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 [0.0, 0.044642857142857144, 0.03409090909090909, 0.15234375] [nan, 1.0, 1.0, 1.0]\n",
      "0 [0.4329896907216495, 0.44642857142857145, 0.8181818181818182, 0.30859375] [0.9545454545454546, 0.9803921568627451, 1.0, 0.9875]\n",
      "1 [0.4536082474226804, 0.49107142857142855, 0.8181818181818182, 0.31640625] [0.9565217391304348, 0.9821428571428571, 1.0, 0.9878048780487805]\n"
     ]
    }
   ],
   "source": [
    "#Too strong regularization results in not PREDICTING any positives. Specifically:\n",
    "\n",
    "for i in range(-5, 2):\n",
    "    c = 10**i\n",
    "    clf = SVC(C = c)\n",
    "    fc = forward_chain(clf)\n",
    "    print(i, fc[0], fc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25...0.5...0.75...0...1...2..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for c in [0.25, 0.5, 0.75]:\n",
    "    print(\"%s...\" % c, end = '')\n",
    "    clf = SVC(C = c)\n",
    "    rec, pre = forward_chain(clf)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = c)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = c)\n",
    "    \n",
    "for i in range(0, 3):\n",
    "    c = 10**i\n",
    "    print(\"%s...\" % i, end = '')\n",
    "    clf = SVC(C = c)\n",
    "    rec, pre = forward_chain(clf)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = \"10^%s\" % i)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = \"10^%s\" % i)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"SVM with Varying C\")\n",
    "plt.savefig('images/ch-misinformation/ml_svm.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3...6...9...12...15...18...21...24..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for md in [3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "    print(\"%s...\" % md, end = '')\n",
    "    clf = tree.DecisionTreeClassifier(max_depth = md)\n",
    "    rec, pre = forward_chain(clf)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = md)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = md)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"Decision Trees of Varying Depths\")\n",
    "plt.savefig('images/ch-misinformation/ml_dt.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:9: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9...12...15...18...21...24..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for md in [3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "    print(\"%s...\" % md, end = '')\n",
    "    clf = RandomForestClassifier(max_depth = md)\n",
    "    rec, pre = forward_chain(clf)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = md)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = md)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"Random Forest Classifier of Varying Depths\")\n",
    "plt.savefig('images/ch-misinformation/ml_rf.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3...6...9...12...15...18...21...24..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for kn in [3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "    print(\"%s...\" % kn, end = '')\n",
    "    clf = KNeighborsClassifier(n_neighbors = kn)\n",
    "    rec, pre = forward_chain(clf)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = kn)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = kn)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"K-Nearest Neighbors Classifier\")\n",
    "plt.savefig('images/ch-misinformation/ml_knn.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x['wordlength'] = df_x['text'].apply(lambda x: x.count(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns (recall, precision)\n",
    "def rec_pre_wl(trn, tst, clf):\n",
    "    X_trn = vectorizer.fit_transform(trn['token'])\n",
    "    X_tst = vectorizer.transform(tst['token'])\n",
    "    \n",
    "    wl_trn = scaler.fit_transform(trn['text'].apply(lambda x: x.count(\" \")).values.reshape(-1, 1))\n",
    "    wl_tst = scaler.fit_transform(tst['text'].apply(lambda x: x.count(\" \")).values.reshape(-1, 1))\n",
    "    \n",
    "    X_trn = hstack([X_trn, wl_trn])\n",
    "    X_tst = hstack([X_tst, wl_tst])\n",
    "\n",
    "    clf.fit(X_trn, trn['scam'])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(tst['scam'], clf.predict(X_tst)).ravel()\n",
    "    return tp / (tp + fn), tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7...0.85...0...1...2...3...4..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for c in [0.7, 0.85]:\n",
    "    print(\"%s...\" % c, end = '')\n",
    "    clf = LogisticRegression(C = c)\n",
    "    rec, pre = forward_chain(clf, rec_pre_wl)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = c)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = c)\n",
    "    \n",
    "for i in range(0, 5):\n",
    "    c = 10**i\n",
    "    print(\"%s...\" % i, end = '')\n",
    "    clf = LogisticRegression(C = c)\n",
    "    rec, pre = forward_chain(clf, rec_pre_wl)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = \"10^%s\" % i)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = \"10^%s\" % i)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"Logistic Regression with Varying C ($L_2$ Regularization)\\nUsing Tokens + # of Words\")\n",
    "plt.savefig('images/ch-misinformation/ml_log_wl.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25...0.5...0.75...0...1...2..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for c in [0.25, 0.5, 0.75]:\n",
    "    print(\"%s...\" % c, end = '')\n",
    "    clf = SVC(C = c)\n",
    "    rec, pre = forward_chain(clf, rec_pre_wl)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = c)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = c)\n",
    "    \n",
    "for i in range(0, 3):\n",
    "    c = 10**i\n",
    "    print(\"%s...\" % i, end = '')\n",
    "    clf = SVC(C = c)\n",
    "    rec, pre = forward_chain(clf, rec_pre_wl)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = \"10^%s\" % i)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = \"10^%s\" % i)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"SVM with Varying C\\nUsing Tokens + # of Words\")\n",
    "plt.savefig('images/ch-misinformation/ml_svm_wl.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3...6...9...12...15...18...21...24..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for md in [3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "    print(\"%s...\" % md, end = '')\n",
    "    clf = tree.DecisionTreeClassifier(max_depth = md)\n",
    "    rec, pre = forward_chain(clf, rec_pre_wl)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = md)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = md)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"Decision Trees of Varying Depths\\nUsing Tokens + # of Words\")\n",
    "plt.savefig('images/ch-misinformation/ml_dt_wl.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3...6...9...12...15...18...21...24..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for kn in [3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "    print(\"%s...\" % kn, end = '')\n",
    "    clf = KNeighborsClassifier(n_neighbors = kn)\n",
    "    rec, pre = forward_chain(clf, rec_pre_wl)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = kn)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = kn)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"K-Nearest Neighbors Classifier\\nUsing Tokens + # of Words\")\n",
    "plt.savefig('images/ch-misinformation/ml_knn_wl.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using user country code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns (recall, precision)\n",
    "def rec_pre_cc(trn, tst, clf):\n",
    "    X_trn = vectorizer.fit_transform(trn['token'])\n",
    "    X_tst = vectorizer.transform(tst['token'])\n",
    "    \n",
    "    co_trn = trn['tel'].str.startswith('+57 ').values.reshape(-1, 1)\n",
    "    vz_trn = trn['tel'].str.startswith('+58 ').values.reshape(-1, 1)\n",
    "    \n",
    "    co_tst = tst['tel'].str.startswith('+57 ').values.reshape(-1, 1)\n",
    "    vz_tst = tst['tel'].str.startswith('+58 ').values.reshape(-1, 1)\n",
    "    \n",
    "    X_trn = hstack([X_trn, co_trn, vz_trn])\n",
    "    X_tst = hstack([X_tst, co_tst, vz_tst])\n",
    "\n",
    "    clf.fit(X_trn, trn['scam'])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(tst['scam'], clf.predict(X_tst)).ravel()\n",
    "    return tp / (tp + fn), tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7...0.85...0...1...2..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for c in [0.7, 0.85]:\n",
    "    print(\"%s...\" % c, end = '')\n",
    "    clf = LogisticRegression(C = c)\n",
    "    rec, pre = forward_chain(clf, rec_pre_cc)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = c)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = c)\n",
    "    \n",
    "for i in range(0, 5):\n",
    "    c = 10**i\n",
    "    print(\"%s...\" % i, end = '')\n",
    "    clf = LogisticRegression(C = c)\n",
    "    rec, pre = forward_chain(clf, rec_pre_cc)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = \"10^%s\" % i)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = \"10^%s\" % i)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"Logistic Regression with Varying C ($L_2$ Regularization)\\nUsing Tokens + User Country Code\")\n",
    "plt.savefig('images/ch-misinformation/ml_log_cc.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25...0.5...0.75...0...1...2..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for c in [0.25, 0.5, 0.75]:\n",
    "    print(\"%s...\" % c, end = '')\n",
    "    clf = SVC(C = c)\n",
    "    rec, pre = forward_chain(clf, rec_pre_cc)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = c)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = c)\n",
    "    \n",
    "for i in range(0, 3):\n",
    "    c = 10**i\n",
    "    print(\"%s...\" % i, end = '')\n",
    "    clf = SVC(C = c)\n",
    "    rec, pre = forward_chain(clf, rec_pre_cc)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = \"10^%s\" % i)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = \"10^%s\" % i)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"SVM with Varying C\\nUsing Tokens + User Country Code\")\n",
    "plt.savefig('images/ch-misinformation/ml_svm_cc.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3...6...9...12...15...18...21...24..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for md in [3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "    print(\"%s...\" % md, end = '')\n",
    "    clf = tree.DecisionTreeClassifier(max_depth = md)\n",
    "    rec, pre = forward_chain(clf, rec_pre_cc)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = md)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = md)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"Decision Trees of Varying Depths\\nUsing Tokens + User Country Code\")\n",
    "plt.savefig('images/ch-misinformation/ml_dt_cc.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3...6...9...12...15...18...21...24..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for kn in [3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "    print(\"%s...\" % kn, end = '')\n",
    "    clf = KNeighborsClassifier(n_neighbors = kn)\n",
    "    rec, pre = forward_chain(clf, rec_pre_cc)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = kn)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = kn)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"K-Nearest Neighbors Classifier\\nUsing Tokens + User Country Code\")\n",
    "plt.savefig('images/ch-misinformation/ml_knn_cc.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using group information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174, 66)\n"
     ]
    }
   ],
   "source": [
    "df_groups = pd.read_csv(\"Data/df_groups_nb3b-virality.csv\", index_col = 0)\n",
    "print(df_groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_hhConc = df_groups['hhConc'].to_dict()\n",
    "group_gini = df_groups['gini'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "//anaconda3/envs/vzwa/lib/python3.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_train['hhConc'] = df_train['uid'].apply(lambda x: group_hhConc[x])\n",
    "df_train['gini'] = df_train['uid'].apply(lambda x: group_gini[x])\n",
    "\n",
    "df_test['hhConc'] = df_test['uid'].apply(lambda x: group_hhConc[x])\n",
    "df_test['gini'] = df_test['uid'].apply(lambda x: group_gini[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns (recall, precision)\n",
    "def rec_pre_group(trn, tst, clf):\n",
    "    X_trn = vectorizer.fit_transform(trn['token'])\n",
    "    X_tst = vectorizer.transform(tst['token'])\n",
    "    \n",
    "    conc_trn = trn['hhConc'].values.reshape(-1, 1)\n",
    "    gini_trn = trn['gini'].values.reshape(-1, 1)\n",
    "    \n",
    "    conc_tst = tst['hhConc'].values.reshape(-1, 1)\n",
    "    gini_tst = tst['gini'].values.reshape(-1, 1)\n",
    "    \n",
    "    X_trn = hstack([X_trn, conc_trn, gini_trn])\n",
    "    X_tst = hstack([X_tst, conc_tst, gini_tst])\n",
    "\n",
    "    clf.fit(X_trn, trn['scam'])\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(tst['scam'], clf.predict(X_tst)).ravel()\n",
    "    return tp / (tp + fn), tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7...0.85...0...1...2...3...4..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for c in [0.7, 0.85]:\n",
    "    print(\"%s...\" % c, end = '')\n",
    "    clf = LogisticRegression(C = c)\n",
    "    rec, pre = forward_chain(clf, rec_pre_group)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = c)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = c)\n",
    "    \n",
    "for i in range(0, 5):\n",
    "    c = 10**i\n",
    "    print(\"%s...\" % i, end = '')\n",
    "    clf = LogisticRegression(C = c)\n",
    "    rec, pre = forward_chain(clf, rec_pre_group)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = \"10^%s\" % i)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = \"10^%s\" % i)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"Logistic Regression with Varying C ($L_2$ Regularization)\\nUsing Tokens + Group Concentration, Inequality\")\n",
    "plt.savefig('images/ch-misinformation/ml_log_group.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25...0.5...0.75...0...1...2..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for c in [0.25, 0.5, 0.75]:\n",
    "    print(\"%s...\" % c, end = '')\n",
    "    clf = SVC(C = c)\n",
    "    rec, pre = forward_chain(clf, rec_pre_group)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = c)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = c)\n",
    "    \n",
    "for i in range(0, 3):\n",
    "    c = 10**i\n",
    "    print(\"%s...\" % i, end = '')\n",
    "    clf = SVC(C = c)\n",
    "    rec, pre = forward_chain(clf, rec_pre_group)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = \"10^%s\" % i)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = \"10^%s\" % i)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"SVM with Varying C\\nUsing Tokens + Group Concentration, Inequality\")\n",
    "plt.savefig('images/ch-misinformation/ml_svm_group.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3...6...9...12...15...18...21...24..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for md in [3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "    print(\"%s...\" % md, end = '')\n",
    "    clf = tree.DecisionTreeClassifier(max_depth = md)\n",
    "    rec, pre = forward_chain(clf, rec_pre_group)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = md)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = md)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"Decision Trees of Varying Depths\\nUsing Tokens + Group Concentration, Inequality\")\n",
    "plt.savefig('images/ch-misinformation/ml_dt_group.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3...6...9...12...15...18...21...24..."
     ]
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 8))\n",
    "\n",
    "for kn in [3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "    print(\"%s...\" % kn, end = '')\n",
    "    clf = KNeighborsClassifier(n_neighbors = kn)\n",
    "    rec, pre = forward_chain(clf, rec_pre_group)\n",
    "    ax1.plot([1, 2, 3, 4], rec, label = kn)\n",
    "    ax2.plot([1, 2, 3, 4], pre, label = kn)\n",
    "    \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_xlabel(\"Training Size / Validation Size\")\n",
    "ax2.set_xlabel(\"Training Size / Validation Size\")\n",
    "\n",
    "ax1.set_ylabel(\"Recall (Detected / Actual Scams)\")\n",
    "ax2.set_ylabel(\"Precision (Actual / Flagged Scams)\")\n",
    "\n",
    "plt.suptitle(\"K-Nearest Neighbors Classifier\\nUsing Tokens + Group Concentration, Inequality\")\n",
    "plt.savefig('images/ch-misinformation/ml_knn_group.png', bbox_inches = 'tight', pad_inches = 0.05)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(df_train['token'])\n",
    "X_test = vectorizer.transform(df_test['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8637   11]\n",
      " [  49  103]]\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 3)\n",
    "clf.fit(X_train, df_train['scam'])\n",
    "\n",
    "print(confusion_matrix(df_test['scam'], clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8641    7]\n",
      " [  94   58]]\n"
     ]
    }
   ],
   "source": [
    "wl_train = scaler.fit_transform(df_train['text'].apply(lambda x: x.count(\" \")).values.reshape(-1, 1))\n",
    "wl_test = scaler.fit_transform(df_test['text'].apply(lambda x: x.count(\" \")).values.reshape(-1, 1))\n",
    "\n",
    "co_train = df_train['tel'].str.startswith('+57 ').values.reshape(-1, 1)\n",
    "vz_train = df_train['tel'].str.startswith('+58 ').values.reshape(-1, 1)\n",
    "\n",
    "co_test = df_test['tel'].str.startswith('+57 ').values.reshape(-1, 1)\n",
    "vz_test = df_test['tel'].str.startswith('+58 ').values.reshape(-1, 1)\n",
    "\n",
    "X_train_stack = hstack([X_train, co_train, vz_train, wl_train])\n",
    "X_test_stack = hstack([X_test, co_test, vz_test, wl_test])\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 12)\n",
    "clf.fit(X_train_stack, df_train['scam'])\n",
    "\n",
    "print(confusion_matrix(df_test['scam'], clf.predict(X_test_stack)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8638   10]\n",
      " [ 114   38]]\n"
     ]
    }
   ],
   "source": [
    "wl_train = scaler.fit_transform(df_train['text'].apply(lambda x: x.count(\" \")).values.reshape(-1, 1))\n",
    "wl_test = scaler.fit_transform(df_test['text'].apply(lambda x: x.count(\" \")).values.reshape(-1, 1))\n",
    "\n",
    "co_train = df_train['tel'].str.startswith('+57 ').values.reshape(-1, 1)\n",
    "vz_train = df_train['tel'].str.startswith('+58 ').values.reshape(-1, 1)\n",
    "\n",
    "co_test = df_test['tel'].str.startswith('+57 ').values.reshape(-1, 1)\n",
    "vz_test = df_test['tel'].str.startswith('+58 ').values.reshape(-1, 1)\n",
    "\n",
    "X_train_stack = hstack([X_train, co_train, vz_train, wl_train])\n",
    "X_test_stack = hstack([X_test, co_test, vz_test, wl_test])\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "clf.fit(X_train_stack, df_train['scam'])\n",
    "\n",
    "print(confusion_matrix(df_test['scam'], clf.predict(X_test_stack)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_31624 <= 0.08\n",
      "|   |--- feature_34343 <= 0.24\n",
      "|   |   |--- feature_15932 <= 0.11\n",
      "|   |   |   |--- class: False\n",
      "|   |   |--- feature_15932 >  0.11\n",
      "|   |   |   |--- class: True\n",
      "|   |--- feature_34343 >  0.24\n",
      "|   |   |--- feature_42906 <= -0.18\n",
      "|   |   |   |--- class: False\n",
      "|   |   |--- feature_42906 >  -0.18\n",
      "|   |   |   |--- class: True\n",
      "|--- feature_31624 >  0.08\n",
      "|   |--- feature_10757 <= 0.05\n",
      "|   |   |--- feature_9357 <= 0.06\n",
      "|   |   |   |--- class: True\n",
      "|   |   |--- feature_9357 >  0.06\n",
      "|   |   |   |--- class: False\n",
      "|   |--- feature_10757 >  0.05\n",
      "|   |   |--- class: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_rules = export_text(clf)\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_names = vectorizer.get_feature_names() + ['CO User', 'VZ User', '# Words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile = open(\"images/ch-misinformation/tree.dot\", 'w')\n",
    "export_graphviz(clf, out_file=dotfile, feature_names=token_names)\n",
    "dotfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_vzwa)",
   "language": "python",
   "name": "conda_vzwa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
